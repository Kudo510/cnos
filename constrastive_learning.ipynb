{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Create dataset\n",
    "Use Sam to extract proposals from input images (100 images) then for proposals with same regions as the ground truth masks, they are considered as positive sameple to the templates ( use the BlenderProc 42 templates), negative otherwise\n",
    "\n",
    "Run through 100 images - then return positive proposals and negative proposals\n",
    "\n",
    "Use IoU >0.5 to get the postive proposals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-08-13 12:49:14,582] [INFO] src.model.constrastive_learning: loading sam\n",
      "[2024-08-13 12:49:14,583] [INFO] root: Loading SAM model from datasets/bop23_challenge/pretrained/segment-anything\n",
      "[2024-08-13 12:49:17,149] [INFO] root: Init CustomSamAutomaticMaskGenerator done!\n",
      "[2024-08-13 12:49:21,764] [INFO] src.model.constrastive_learning: The best for 0th mask is at index 3 with an IoU of 0.884139219808456\n",
      "[2024-08-13 12:49:21,795] [INFO] src.model.constrastive_learning: The best for 1th mask is at index 29 with an IoU of 0.8490939977349944\n",
      "[2024-08-13 12:49:21,827] [INFO] src.model.constrastive_learning: The best for 2th mask is at index 30 with an IoU of 0.7815985130111525\n",
      "[2024-08-13 12:49:21,858] [INFO] src.model.constrastive_learning: The best for 3th mask is at index 55 with an IoU of 0.8901230861603122\n",
      "[2024-08-13 12:49:21,890] [INFO] src.model.constrastive_learning: The best for 4th mask is at index 23 with an IoU of 0.6603650586701434\n",
      "[2024-08-13 12:49:21,922] [INFO] src.model.constrastive_learning: The best for 5th mask is at index 7 with an IoU of 0.912324994262107\n",
      "[2024-08-13 12:49:21,953] [INFO] src.model.constrastive_learning: The best for 6th mask is at index 71 with an IoU of 0.9009450472523626\n",
      "[2024-08-13 12:49:21,985] [INFO] src.model.constrastive_learning: The best for 7th mask is at index 61 with an IoU of 0.9028042472093657\n",
      "[2024-08-13 12:49:22,017] [INFO] src.model.constrastive_learning: The best for 8th mask is at index 10 with an IoU of 0.8701483117702745\n",
      "[2024-08-13 12:49:22,048] [INFO] src.model.constrastive_learning: The best for 9th mask is at index 47 with an IoU of 0.9017586416009703\n",
      "[2024-08-13 12:49:22,080] [INFO] src.model.constrastive_learning: The best for 10th mask is at index 20 with an IoU of 0.7711993888464477\n",
      "[2024-08-13 12:49:22,112] [INFO] src.model.constrastive_learning: The best for 11th mask is at index 43 with an IoU of 0.9090539165818922\n",
      "[2024-08-13 12:49:22,144] [INFO] src.model.constrastive_learning: The best for 12th mask is at index 25 with an IoU of 0.873224618621778\n",
      "[2024-08-13 12:49:22,176] [INFO] src.model.constrastive_learning: The best for 13th mask is at index 22 with an IoU of 0.9206318995051389\n",
      "[2024-08-13 12:49:22,208] [INFO] src.model.constrastive_learning: The best for 14th mask is at index 2 with an IoU of 0.8564285714285714\n",
      "[2024-08-13 12:49:22,239] [INFO] src.model.constrastive_learning: The best for 15th mask is at index 81 with an IoU of 0.6432197244379986\n",
      "[2024-08-13 12:49:22,272] [INFO] src.model.constrastive_learning: The best for 16th mask is at index 87 with an IoU of 0.29010989010989013\n",
      "[2024-08-13 12:49:22,305] [INFO] src.model.constrastive_learning: The best for 17th mask is at index 74 with an IoU of 0.526595744680851\n",
      "[2024-08-13 12:49:22,337] [INFO] src.model.constrastive_learning: The best for 18th mask is at index 100 with an IoU of 0.1873198847262248\n"
     ]
    }
   ],
   "source": [
    "from src.model.constrastive_learning import extract_dataset\n",
    "\n",
    "dataset=\"icbin\"\n",
    "data_type=\"test\"\n",
    "scene_id=1\n",
    "pos_proposals, neg_proposals = extract_dataset(dataset, data_type, scene_id) # Take 2.21 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos_proposals[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pos_proposals = [item for sublist in pos_proposals for item in sublist]\n",
    "all_neg_proposals = [item for sublist in neg_proposals for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "obj_id = 1\n",
    "template_path = f\"datasets/bop23_challenge/datasets/templates_pyrender/{dataset}/obj_{obj_id:06d}\"\n",
    "template_files = sorted(glob.glob(os.path.join(template_path, \"*.png\")), key=os.path.getmtime)\n",
    "templates = [np.array(Image.open(template_file).convert(\"RGB\"))[ :, :, :3] for template_file in template_files] # This image has 4 channels- the last one is not crucial - maybe about opacity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Process dataset\n",
    "Build train_dataset as postive, negative pairs\n",
    "Then build train_loader\n",
    "\n",
    "Organize your images into classes. You'll need positive pairs (same class) and negative pairs (different classes) for training.\n",
    "Resize/pad image to 224*224  then /255.0\n",
    "then transform the image (also with std, mean as in ImageNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.constrastive_learning import PairedDataset\n",
    "\n",
    "# Custom dataset for paired images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model\n",
    "\n",
    "Two Approaches\n",
    "\n",
    "    Extract features from Dinov2 as in cnos\n",
    "    \n",
    "    Extract BoW vectors as in FoundPose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.constrastive_learning import ContrastiveModel\n",
    "\n",
    "model = ContrastiveModel()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Implement contrastive loss function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Contrastive loss function\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mContrastiveLoss\u001b[39;00m(\u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m):\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28msuper\u001b[39m(ContrastiveLoss, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "# Contrastive loss function\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        euclidean_distance = nn.functional.pairwise_distance(output1, output2)\n",
    "        loss = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n",
    "                          (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Create data pairs for training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
