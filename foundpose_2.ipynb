{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Patch descriptors register in 3D for 642 templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "# Load templates\n",
    "template_path = \"datasets/bop23_challenge/datasets/templates_pyrender/icbin_642/obj_000001\"\n",
    "template_files = sorted(glob.glob(os.path.join(template_path, \"*.png\")), key=os.path.getmtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "templates = [np.array(Image.open(template_file).convert(\"RGB\").resize((420,420)))[:,:,:3] for template_file in template_files] # This image has 4 channels- the last one is not crucial - maybe about opacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "def patches_feature_extraction(template_patches, dinov2_vitl14, device):\n",
    "    # crop_rgb: numpy array\n",
    "    # temps = np.transpose(np.array(template_patches), (0,2,3,1))\n",
    "    rgb_normalize = T.Compose(\n",
    "        [\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ]\n",
    "    )\n",
    "    normalized_patches = torch.stack([rgb_normalize(patch) for patch in template_patches])\n",
    "    layers_list = list(range(18))\n",
    "    torch.cuda.empty_cache()\n",
    "    with torch.no_grad(): \n",
    "        feature_patches= dinov2_vitl14.module.get_intermediate_layers(normalized_patches.to(device), n=layers_list, reshape=True)\n",
    "    return feature_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/cuong.vandam/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "/home/cuong.vandam/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is available (SwiGLU)\")\n",
      "/home/cuong.vandam/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)\n",
      "  warnings.warn(\"xFormers is available (Attention)\")\n",
      "/home/cuong.vandam/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)\n",
      "  warnings.warn(\"xFormers is available (Block)\")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dinov2_vitl14 = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitl14')\n",
    "dinov2_vitl14.patch_size = 14\n",
    "if torch.cuda.is_available():\n",
    "    dinov2_vitl14 = torch.nn.DataParallel(dinov2_vitl14).to(device)  # Use DataParallel for multiple GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "template_batches = [templates[i:i+batch_size] for i in range(0, len(templates), batch_size)]\n",
    "patch_features= list()\n",
    "\n",
    "for batch in template_batches:\n",
    "    torch.cuda.empty_cache()\n",
    "    batch_feature = patches_feature_extraction(batch, dinov2_vitl14, device)\n",
    "    patch_features.append(batch_feature[0].to('cpu'))\n",
    "    del batch_feature\n",
    "    \n",
    "patch_features = torch.cat(patch_features).permute(0,2,3,1).view(-1,30*30,1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dinov2_vitl14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([642, 900, 1024])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patch_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19260, 1024])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Given only 30 first patches are valid\n",
    "valid_patch_features = patch_features[:, :30,].reshape(-1,1024)\n",
    "valid_patch_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "642 [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30]\n"
     ]
    }
   ],
   "source": [
    "# Number of valid patches on each template - here given 30 for each templates\n",
    "num_valid_patches = [30]*642\n",
    "print(len(num_valid_patches), num_valid_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19260, 256)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Apply PCA with the 256 components to reduce dimensionality of the features\n",
    "pca = PCA(n_components=256)\n",
    "pca_patches_descriptors = pca.fit_transform(np.array(valid_patch_features.cpu()))\n",
    "pca_patches_descriptors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Perform Kmean clustering for all patch descriptors from templates (2048 clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering 19260 points in 256D to 2048 clusters, redo 1 times, 20 iterations\n",
      "  Preprocessing in 0.00 s\n",
      "  Iteration 19 (0.13 s, search 0.08 s): objective=4683.79 imbalance=1.247 nsplit=0       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING clustering 19260 points to 2048 centroids: please provide at least 79872 training points\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4683.7861328125"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://github.com/facebookresearch/faiss/wiki/Faiss-building-blocks:-clustering,-PCA,-quantization\n",
    "import faiss\n",
    "ncentroids = 2048\n",
    "niter = 20\n",
    "verbose = True\n",
    "d = pca_patches_descriptors.shape[1]\n",
    "kmeans = faiss.Kmeans(d, ncentroids, niter=niter, verbose=verbose, gpu=True)\n",
    "kmeans.train(pca_patches_descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19260, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign labels to the data points\n",
    "labels = kmeans.index.search(pca_patches_descriptors, 1)[1]\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates_labels = list()\n",
    "start_idx = 0\n",
    "for num in num_valid_patches:\n",
    "    end_idx = start_idx + num\n",
    "    template_labels = labels[start_idx:end_idx].reshape(-1)\n",
    "    templates_labels.append(template_labels)\n",
    "    start_idx = end_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def calculate_templates_vector(templates_labels, num_clusters = 2048):\n",
    "    # Calculate bag-of-words descriptors of the templates\n",
    "\n",
    "    templates_vector = list()\n",
    "    all_occurrences = [np.bincount(templates_label, minlength=2048) for templates_label in templates_labels]\n",
    "    ni_array = np.sum(np.array(all_occurrences), axis = 0)\n",
    "    N = len(templates_labels) # Number of templates\n",
    "    for t in range(len(templates_labels)):\n",
    "        template_vector = list()\n",
    "        occurrences = np.bincount(templates_labels[t], minlength=2048)\n",
    "        for i in range(num_clusters):\n",
    "            n_it = occurrences[i]\n",
    "            nt = len(templates_labels[t])\n",
    "            ni = ni_array[i]\n",
    "            bi = n_it / nt * math.log(N / ni)\n",
    "            template_vector.append(bi)\n",
    "        templates_vector.append(np.array(template_vector))\n",
    "    return templates_vector\n",
    "templates_vector = calculate_templates_vector(templates_labels = templates_labels, num_clusters = 2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19238137077100054"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(templates_vector[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Retrieving similar templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image crop \n",
    "crop_rgb = np.array(Image.open(\"cnos_analysis/crop_proposals/crop1.png\").convert(\"RGB\").resize((420,420))) # (124, 157, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(420, 420, 3)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crop_rgb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/cuong.vandam/.cache/torch/hub/facebookresearch_dinov2_main\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dinov2_vitl14 = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitl14')\n",
    "dinov2_vitl14.patch_size = 14\n",
    "if torch.cuda.is_available():\n",
    "    dinov2_vitl14 = torch.nn.DataParallel(dinov2_vitl14).to(device)  # Use DataParallel for multiple GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_feature = patches_feature_extraction(np.expand_dims(crop_rgb, 0), dinov2_vitl14, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dinov2_vitl14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([400, 1024])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_crop_features = crop_feature[0].permute(0,2,3,1).reshape(30*30,-1)[:400,:]\n",
    "valid_crop_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 256)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=256)\n",
    "pca_crop_patches_descriptors = pca.fit_transform(np.array(valid_crop_features.cpu()))\n",
    "pca_crop_patches_descriptors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign labels to the data points\n",
    "crop_labels = kmeans.index.search(pca_crop_patches_descriptors, 1)[1].reshape(-1)\n",
    "crop_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_350848/2790732940.py:17: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  bi = n_it / nt * math.log(N / ni)\n",
      "/tmp/ipykernel_350848/2790732940.py:17: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  bi = n_it / nt * math.log(N / ni)\n"
     ]
    }
   ],
   "source": [
    "crop_vector = calculate_templates_vector(templates_labels = [crop_labels], num_clusters = 2048)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# For word_i, term frequency = occurences of word_i within the crop / number of occurences of word_i in all templates). \n",
    "def calculate_crop_vector(crop_labels, templates_labels, num_clusters = 2048):\n",
    "    # Calculate bag-of-words descriptors of the templates\n",
    "    all_occurrences_crop = np.bincount(crop_labels, minlength=2048)\n",
    "\n",
    "    all_occurrences_templates = [np.bincount(templates_label, minlength=2048) for templates_label in templates_labels]\n",
    "    ni_array = np.sum(np.array(all_occurrences_templates), axis = 0)\n",
    "    N = len(templates_labels) # Number of templates = 642 \n",
    "\n",
    "    crop_vector = list()\n",
    "    for i in range(num_clusters):\n",
    "        n_it = all_occurrences_crop[i]\n",
    "        nt = crop_labels.shape[0] # Number of words in crop = 400 \n",
    "        ni = ni_array[i]\n",
    "        bi = n_it / nt * math.log(N / ni)\n",
    "        crop_vector.append(bi)\n",
    "    return crop_vector\n",
    "crop_vector = calculate_crop_vector(crop_labels = crop_labels, templates_labels = templates_labels, num_clusters = 2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, value in enumerate(crop_vector):\n",
    "#     if value>0:\n",
    "#         print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
